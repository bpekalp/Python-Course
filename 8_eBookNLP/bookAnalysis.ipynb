{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read The Book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datas/miracle_in_the_andes.txt\", \"r\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Many Chapters Are There?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Using String Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 chapters in the book.\n"
     ]
    }
   ],
   "source": [
    "chapterCount = book.count(\"Chapter\")\n",
    "print(f\"There are {chapterCount} chapters in the book.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Using Regular Expressions (Regex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 chapters in the book.\n",
      "Found chapters are:\n",
      "Chapter 1\n",
      "Chapter 2\n",
      "Chapter 3\n",
      "Chapter 4\n",
      "Chapter 5\n",
      "Chapter 6\n",
      "Chapter 7\n",
      "Chapter 8\n",
      "Chapter 9\n",
      "Chapter 10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(\"Chapter [0-9]+\")\n",
    "foundPatterns = re.findall(pattern, book)\n",
    "chapterCount = len(foundPatterns)\n",
    "print(f\"There are {chapterCount} chapters in the book.\")\n",
    "print(\"Found chapters are:\")\n",
    "for element in foundPatterns:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Every Sentence That Contains The Word \"Love\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 67 sentences with the word 'love' in them.\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(\"[A-Z]{1}[^.]*[^A-Za-z]+love[^A-Za-z]+[^.]*.\")\n",
    "foundPatterns = re.findall(pattern, book)\n",
    "sentenceCount = len(foundPatterns)\n",
    "print(f\"There are {sentenceCount} sentences with the word 'love' in them.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are The Most Used Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86798 words in the book.\n",
      "Top five words are:\n",
      "'the' with count of 5346\n",
      "Frequency: 0.06159128\n",
      "Probability: 6.1591%\n",
      "\n",
      "'and' with count of 2795\n",
      "Frequency: 0.03220120\n",
      "Probability: 3.2201%\n",
      "\n",
      "'i' with count of 2729\n",
      "Frequency: 0.03144082\n",
      "Probability: 3.1441%\n",
      "\n",
      "'to' with count of 2400\n",
      "Frequency: 0.02765041\n",
      "Probability: 2.7650%\n",
      "\n",
      "'of' with count of 2060\n",
      "Frequency: 0.02373327\n",
      "Probability: 2.3733%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(\"[A-Za-z]+\")\n",
    "foundPatterns = re.findall(pattern, book.lower())\n",
    "wordAmount = len(foundPatterns)\n",
    "print(f\"There are {wordAmount} words in the book.\")\n",
    "\n",
    "import collections\n",
    "\n",
    "wordCounts = collections.Counter(foundPatterns)\n",
    "\n",
    "print(\"Top five words are:\")\n",
    "for word, count in wordCounts.most_common(5):\n",
    "    frequency = count / wordAmount\n",
    "    perc = frequency * 100.0\n",
    "\n",
    "    print(f\"'{word}' with count of {count}\")\n",
    "    print(f\"Frequency: {frequency:.8f}\")\n",
    "    print(f\"Probability: {perc:.4f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Out The Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top five words are:\n",
      "'would' with count of 575\n",
      "Frequency: 0.00662458\n",
      "Probability: 0.6625%\n",
      "\n",
      "'us' with count of 519\n",
      "Frequency: 0.00597940\n",
      "Probability: 0.5979%\n",
      "\n",
      "'said' with count of 292\n",
      "Frequency: 0.00336413\n",
      "Probability: 0.3364%\n",
      "\n",
      "'roberto' with count of 284\n",
      "Frequency: 0.00327196\n",
      "Probability: 0.3272%\n",
      "\n",
      "'could' with count of 252\n",
      "Frequency: 0.00290329\n",
      "Probability: 0.2903%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gbpekalp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "engStopWords = stopwords.words(\"english\")\n",
    "\n",
    "pattern = re.compile(\"[A-Za-z]+\")\n",
    "foundPatterns = re.findall(pattern, book.lower())\n",
    "\n",
    "filteredPatterns = [element for element in foundPatterns if element not in engStopWords]\n",
    "\n",
    "wordCounts = collections.Counter(filteredPatterns)\n",
    "\n",
    "print(\"Top five words are:\")\n",
    "for word, count in wordCounts.most_common(5):\n",
    "    frequency = count / wordAmount\n",
    "    perc = frequency * 100.0\n",
    "\n",
    "    print(f\"'{word}' with count of {count}\")\n",
    "    print(f\"Frequency: {frequency:.8f}\")\n",
    "    print(f\"Probability: {perc:.4f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Positive And Negative Chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive: Chapter 10, Positivity Score: 0.181\n",
      "Most Neutral: Chapter 9, Neutrality Score: 0.824\n",
      "Most Negative: Chapter 3, Negativity Score: 0.145\n",
      "    \n",
      "Chapter 1\n",
      "Positivity: 0.16\n",
      "Neutrality: 0.779\n",
      "Negativitiy: 0.061\n",
      "        \n",
      "Chapter 2\n",
      "Positivity: 0.154\n",
      "Neutrality: 0.726\n",
      "Negativitiy: 0.12\n",
      "        \n",
      "Chapter 3\n",
      "Positivity: 0.105\n",
      "Neutrality: 0.751\n",
      "Negativitiy: 0.145\n",
      "        \n",
      "Chapter 4\n",
      "Positivity: 0.138\n",
      "Neutrality: 0.721\n",
      "Negativitiy: 0.141\n",
      "        \n",
      "Chapter 5\n",
      "Positivity: 0.141\n",
      "Neutrality: 0.742\n",
      "Negativitiy: 0.118\n",
      "        \n",
      "Chapter 6\n",
      "Positivity: 0.115\n",
      "Neutrality: 0.761\n",
      "Negativitiy: 0.124\n",
      "        \n",
      "Chapter 7\n",
      "Positivity: 0.103\n",
      "Neutrality: 0.761\n",
      "Negativitiy: 0.136\n",
      "        \n",
      "Chapter 8\n",
      "Positivity: 0.094\n",
      "Neutrality: 0.786\n",
      "Negativitiy: 0.12\n",
      "        \n",
      "Chapter 9\n",
      "Positivity: 0.079\n",
      "Neutrality: 0.824\n",
      "Negativitiy: 0.097\n",
      "        \n",
      "Chapter 10\n",
      "Positivity: 0.181\n",
      "Neutrality: 0.733\n",
      "Negativitiy: 0.086\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "analyzer = SIA()\n",
    "\n",
    "pattern = re.compile(\"Chapter [0-9]+\")\n",
    "\n",
    "chapterNumbers = re.findall(pattern, book)\n",
    "\n",
    "chapters = re.split(pattern, book)\n",
    "chapters = [chapter.replace(\"\\n\", \" \").strip() for chapter in chapters]\n",
    "chapters = [chapter for chapter in chapters if chapter.strip() != \"\"]\n",
    "\n",
    "results = [analyzer.polarity_scores(chapter) for chapter in chapters]\n",
    "\n",
    "chapterResults = list(zip(chapterNumbers, results))\n",
    "\n",
    "positive = max(chapterResults, key=lambda x: x[1][\"pos\"])\n",
    "neutral = max(chapterResults, key=lambda x: x[1][\"neu\"])\n",
    "negative = max(chapterResults, key=lambda x: x[1][\"neg\"])\n",
    "\n",
    "message = f\"\"\"\\\n",
    "Most Positive: {positive[0]}, Positivity Score: {positive[1][\"pos\"]}\n",
    "Most Neutral: {neutral[0]}, Neutrality Score: {neutral[1][\"neu\"]}\n",
    "Most Negative: {negative[0]}, Negativity Score: {negative[1][\"neg\"]}\n",
    "    \"\"\"\n",
    "\n",
    "print(message)\n",
    "\n",
    "for result in chapterResults:\n",
    "    message = f\"\"\"\\\n",
    "{result[0]}\n",
    "Positivity: {result[1][\"pos\"]}\n",
    "Neutrality: {result[1][\"neu\"]}\n",
    "Negativitiy: {result[1][\"neg\"]}\n",
    "        \"\"\"\n",
    "    print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
